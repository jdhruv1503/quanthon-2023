{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "VWo2G_9wdiNM"
      },
      "source": [
        "## References\n",
        "\n",
        "https://www.kaggle.com/code/mtszkw/technical-indicators-for-trading-stocks\n",
        "<br>\n",
        "https://www.kaggle.com/code/thebrownviking20/everything-you-can-do-with-a-time-series\n",
        "<br>\n",
        "https://www.diva-portal.org/smash/get/diva2:1775077/FULLTEXT01.pdf\n",
        "<br>\n",
        "https://pub.towardsai.net/predicting-stock-prices-using-arima-fourier-transforms-and-technical-indicators-with-deep-43a164859683\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## _Time Series theek krna mat bhoolna_\n",
        "## _Remove weekends Pilich_"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "wRyZc9p6Wmxk"
      },
      "source": [
        "## Import dependencies"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "! pip install -r requirements.txt --quiet"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "H-0FP4sLZFAM"
      },
      "outputs": [],
      "source": [
        "import os\n",
        "import pandas as pd\n",
        "import gdown\n",
        "from datetime import datetime, timedelta\n",
        "\n",
        "from plotly.offline import download_plotlyjs, init_notebook_mode, plot, iplot\n",
        "import plotly as py\n",
        "import plotly.io as pio\n",
        "import plotly.graph_objs as go\n",
        "from plotly.subplots import make_subplots\n",
        "\n",
        "from pmdarima.arima import auto_arima\n",
        "from statsmodels.tsa.arima.model import ARIMA\n",
        "\n",
        "import numpy as np                                    # For matrices!\n",
        "import matplotlib.pyplot as plt                       # To visualize\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.linear_model import LinearRegression     # For the regression itself\n",
        "from sklearn.linear_model import SGDRegressor\n",
        "from sklearn.linear_model import Ridge\n",
        "from sklearn.ensemble import RandomForestRegressor\n",
        "from sklearn.tree import DecisionTreeRegressor\n",
        "from sklearn import svm\n",
        "from sklearn.metrics import mean_squared_error, f1_score\n",
        "from sklearn.preprocessing import OneHotEncoder       # To convert discrete strings to vectors!\n",
        "from sklearn.preprocessing import normalize           # For normalizing\n",
        "import seaborn as sns                                 # For plots"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Change default chart layout"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 17
        },
        "id": "lWGusNNx0Kxs",
        "outputId": "e14a91ae-e65d-428a-dc4b-ddeaaddcda00"
      },
      "outputs": [],
      "source": [
        "# # Show charts when running kernel\n",
        "# init_notebook_mode(connected=True)\n",
        "# \n",
        "# # Change default background color for all visualizations\n",
        "# layout=go.Layout(paper_bgcolor='rgba(0,0,0,0)', plot_bgcolor='rgba(250,250,250,0.8)')\n",
        "# fig = go.Figure(layout=layout)\n",
        "# templated_fig = pio.to_templated(fig)\n",
        "# pio.templates['my_template'] = templated_fig.layout.template\n",
        "# pio.templates.default = 'my_template'"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Download datasets"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "32DbZaSkatlE",
        "outputId": "091003ce-b67a-4b41-fb96-08c80a081bdc"
      },
      "outputs": [],
      "source": [
        "# # SnP500\n",
        "# gdown.download(\"https://docs.google.com/uc?id=1KveL-W2L6YxO-1NKn0n6FeGTKLWgvAL4\", \"ES_continuous_adjusted_1min_2011_2018.txt\", quiet=True)\n",
        "\n",
        "# # Nasdaq\n",
        "# gdown.download(\"https://docs.google.com/uc?id=1NyHRoU2YiaCKIhy7afUTuAmC0haWK1Ny\", \"NQ_continuous_adjusted_1min_2011_2018.txt\", quiet=True)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Read datasets as CSV"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 394
        },
        "id": "nokF9p-qYUno",
        "outputId": "82caac01-cffc-4b1b-b39d-8bd1b72f4d50"
      },
      "outputs": [],
      "source": [
        "ES_1min_raw = pd.read_csv('ES_continuous_adjusted_1min_2011_2018.txt', encoding='latin-1')\n",
        "ES_5min_raw = pd.read_csv('ES_continuous_adjusted_5min_2011_2018.txt', encoding='latin-1')\n",
        "ES_30min_raw = pd.read_csv('ES_continuous_adjusted_30min_2011_2018.txt', encoding='latin-1')\n",
        "ES_1hour_raw = pd.read_csv('ES_continuous_adjusted_1hour_2011_2018.txt', encoding='latin-1')\n",
        "\n",
        "NQ_1min_raw = pd.read_csv('NQ_continuous_adjusted_1min_2011_2018.txt', encoding='latin-1')\n",
        "NQ_5min_raw = pd.read_csv('NQ_continuous_adjusted_5min_2011_2018.txt', encoding='latin-1')\n",
        "NQ_30min_raw = pd.read_csv('NQ_continuous_adjusted_30min_2011_2018.txt', encoding='latin-1')\n",
        "NQ_1hour_raw = pd.read_csv('NQ_continuous_adjusted_1hour_2011_2018.txt', encoding='latin-1')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# Data Processing"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## I. Moving Average\n",
        "\n",
        "Moving Averages (MA) help to smooth out stock prices on a chart by filtering out short-term price fluctuations. We calculate moving averages over a defined period of time e.g. last 9, 50 or 200 days. There are two (most common) averages used in technical analysis which are:\n",
        "\n",
        "- Simple Moving Average (SMA) - a simple average calculated over last N days e.g. 50, 100 or 200,\n",
        "- Exponential Moving Average (EMA) - an average where greater weights are applied to recent prices.\n",
        "MAs and their crossovers (see $Golden\\ Cross$ and $Death\\ Cross$) are often used as trade signals as they are so simple yet powerful."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# SnP500\n",
        "\n",
        "ES_1min_raw['EMA_9'] = ES_1min_raw['Close'].ewm(7200).mean().shift()\n",
        "ES_1min_raw['SMA_50'] = ES_1min_raw['Close'].rolling(72000).mean().shift()\n",
        "ES_1min_raw['SMA_100'] = ES_1min_raw['Close'].rolling(144000).mean().shift()\n",
        "ES_1min_raw['SMA_200'] = ES_1min_raw['Close'].rolling(288000).mean().shift()\n",
        "\n",
        "ES_5min_raw['EMA_9'] = ES_5min_raw['Close'].ewm(1440).mean().shift()\n",
        "ES_5min_raw['SMA_50'] = ES_5min_raw['Close'].rolling(14400).mean().shift()\n",
        "ES_5min_raw['SMA_100'] = ES_5min_raw['Close'].rolling(28800).mean().shift()\n",
        "ES_5min_raw['SMA_200'] = ES_5min_raw['Close'].rolling(57600).mean().shift()\n",
        "\n",
        "ES_30min_raw['EMA_9'] = ES_30min_raw['Close'].ewm(240).mean().shift()\n",
        "ES_30min_raw['SMA_50'] = ES_30min_raw['Close'].rolling(2400).mean().shift()\n",
        "ES_30min_raw['SMA_100'] = ES_30min_raw['Close'].rolling(4800).mean().shift()\n",
        "ES_30min_raw['SMA_200'] = ES_30min_raw['Close'].rolling(9600).mean().shift()\n",
        "\n",
        "ES_1hour_raw['EMA_9'] = ES_1hour_raw['Close'].ewm(120).mean().shift()\n",
        "ES_1hour_raw['SMA_50'] = ES_1hour_raw['Close'].rolling(1200).mean().shift()\n",
        "ES_1hour_raw['SMA_100'] = ES_1hour_raw['Close'].rolling(2400).mean().shift()\n",
        "ES_1hour_raw['SMA_200'] = ES_1hour_raw['Close'].rolling(4800).mean().shift()\n",
        "\n",
        "# Nasdaq\n",
        "\n",
        "NQ_1min_raw['EMA_9'] = NQ_1min_raw['Close'].ewm(7200).mean().shift()\n",
        "NQ_1min_raw['SMA_50'] = NQ_1min_raw['Close'].rolling(72000).mean().shift()\n",
        "NQ_1min_raw['SMA_100'] = NQ_1min_raw['Close'].rolling(144000).mean().shift()\n",
        "NQ_1min_raw['SMA_200'] = NQ_1min_raw['Close'].rolling(288000).mean().shift()\n",
        "\n",
        "NQ_5min_raw['EMA_9'] = NQ_5min_raw['Close'].ewm(1440).mean().shift()\n",
        "NQ_5min_raw['SMA_50'] = NQ_5min_raw['Close'].rolling(14400).mean().shift()\n",
        "NQ_5min_raw['SMA_100'] = NQ_5min_raw['Close'].rolling(28800).mean().shift()\n",
        "NQ_5min_raw['SMA_200'] = NQ_5min_raw['Close'].rolling(57600).mean().shift()\n",
        "\n",
        "NQ_30min_raw['EMA_9'] = NQ_30min_raw['Close'].ewm(240).mean().shift()\n",
        "NQ_30min_raw['SMA_50'] = NQ_30min_raw['Close'].rolling(2400).mean().shift()\n",
        "NQ_30min_raw['SMA_100'] = NQ_30min_raw['Close'].rolling(4800).mean().shift()\n",
        "NQ_30min_raw['SMA_200'] = NQ_30min_raw['Close'].rolling(9600).mean().shift()\n",
        "\n",
        "NQ_1hour_raw['EMA_9'] = NQ_1hour_raw['Close'].ewm(120).mean().shift()\n",
        "NQ_1hour_raw['SMA_50'] = NQ_1hour_raw['Close'].rolling(1200).mean().shift()\n",
        "NQ_1hour_raw['SMA_100'] = NQ_1hour_raw['Close'].rolling(2400).mean().shift()\n",
        "NQ_1hour_raw['SMA_200'] = NQ_1hour_raw['Close'].rolling(4800).mean().shift()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Plotting MA\n",
        "\n",
        "def plotMA(ES_1hour_raw):\n",
        "    fig = go.Figure()\n",
        "    fig.add_trace(go.Scatter(x=ES_1hour_raw.DateTime, y=ES_1hour_raw.EMA_9, name='EMA 9'))\n",
        "    fig.add_trace(go.Scatter(x=ES_1hour_raw.DateTime, y=ES_1hour_raw.SMA_50, name='SMA 50'))\n",
        "    fig.add_trace(go.Scatter(x=ES_1hour_raw.DateTime, y=ES_1hour_raw.SMA_100, name='SMA 100'))\n",
        "    fig.add_trace(go.Scatter(x=ES_1hour_raw.DateTime, y=ES_1hour_raw.SMA_200, name='SMA 200'))\n",
        "    fig.add_trace(go.Scatter(x=ES_1hour_raw.DateTime, y=ES_1hour_raw.Close, name='Close', line_color='dimgray', opacity=0.3))\n",
        "    fig.show()\n",
        "\n",
        "# plotMA(ES_1hour_raw)\n",
        "# plotMA(NQ_1hour_raw)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## II. RSI\n",
        "\n",
        "Another commonly used indicator is a Relative Strength Index (RSI) that indicates magnitude of recent price changes. It can show that a stock is either overbought or oversold. Typically RSI value of 70 and above signal that a stock is becoming overbought/overvalued, meanwhile value of 30 and less can mean that it is oversold. Full range of RSI is from 0 to 100."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "def RSI(df, n=14):\n",
        "    close = df['Close']\n",
        "    delta = close.diff()\n",
        "    delta = delta[1:]\n",
        "    pricesUp = delta.copy()\n",
        "    pricesDown = delta.copy()\n",
        "    pricesUp[pricesUp < 0] = 0\n",
        "    pricesDown[pricesDown > 0] = 0\n",
        "    rollUp = pricesUp.rolling(n).mean()\n",
        "    rollDown = pricesDown.abs().rolling(n).mean()\n",
        "    rs = rollUp / rollDown\n",
        "    rsi = 100.0 - (100.0 / (1.0 + rs))\n",
        "    return rsi\n",
        "\n",
        "# SnP500\n",
        "\n",
        "ES_1min_raw['RSI'] = RSI(ES_1min_raw).fillna(0)\n",
        "ES_5min_raw['RSI'] = RSI(ES_5min_raw).fillna(0)\n",
        "ES_30min_raw['RSI'] = RSI(ES_30min_raw).fillna(0)\n",
        "ES_1hour_raw['RSI'] = RSI(ES_1hour_raw).fillna(0)\n",
        "\n",
        "# Nasdaq\n",
        "\n",
        "NQ_1min_raw['RSI'] = RSI(NQ_1min_raw).fillna(0)\n",
        "NQ_5min_raw['RSI'] = RSI(NQ_5min_raw).fillna(0)\n",
        "NQ_30min_raw['RSI'] = RSI(NQ_30min_raw).fillna(0)\n",
        "NQ_1hour_raw['RSI'] = RSI(NQ_1hour_raw).fillna(0)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Plotting RSI\n",
        "\n",
        "def plotRSI(df):\n",
        "    num_days = len(df)\n",
        "    fig = go.Figure(go.Scatter(x=df.DateTime.tail(num_days), y=df.RSI.tail(num_days)))\n",
        "    fig.add_hline(y=70)\n",
        "    fig.add_hline(y=30)\n",
        "    fig.show()\n",
        "\n",
        "# plotRSI(NQ_1hour_raw)\n",
        "# plotRSI(ES_1hour_raw)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## III. MACD\n",
        "\n",
        "Moving Average Convergence Divergence (MACD) is an indicator which shows the relationship between two exponential moving averages i.e. 12-day and 26-day EMAs. We obtain MACD by substracting 26-day EMA (also called slow EMA) from the 12-day EMA (or fast EMA)."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "def calc_macd(df, timescale):\n",
        "    df[\"EMA_12\"] = pd.Series(df['Close'].ewm(span=12*timescale, min_periods=12).mean())\n",
        "    df[\"EMA_26\"] = pd.Series(df['Close'].ewm(span=26*timescale, min_periods=26).mean())\n",
        "    df[\"MACD\"] = pd.Series(df.EMA_12 - df.EMA_26)\n",
        "    df[\"MACD_signal\"] = pd.Series(df.MACD.ewm(span=9*timescale, min_periods=9).mean())\n",
        "\n",
        "# SnP500\n",
        "\n",
        "calc_macd(ES_1min_raw, 1440)\n",
        "calc_macd(ES_5min_raw, 288)\n",
        "calc_macd(ES_30min_raw, 48)\n",
        "calc_macd(ES_1hour_raw, 24)\n",
        "\n",
        "# Nasdaq\n",
        "\n",
        "calc_macd(NQ_1min_raw, 1440)\n",
        "calc_macd(NQ_5min_raw, 288)\n",
        "calc_macd(NQ_30min_raw, 48)\n",
        "calc_macd(NQ_1hour_raw, 24)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Plotting MACD\n",
        "\n",
        "def plotMACD(df):\n",
        "    fig = make_subplots(rows=2, cols=1)\n",
        "    fig.add_trace(go.Scatter(x=df.DateTime, y=df.Close, name='Close'), row=1, col=1)\n",
        "    fig.add_trace(go.Scatter(x=df.DateTime, y=df.EMA_12, name='EMA 12'), row=1, col=1)\n",
        "    fig.add_trace(go.Scatter(x=df.DateTime, y=df.EMA_26, name='EMA 26'), row=1, col=1)\n",
        "    fig.add_trace(go.Scatter(x=df.DateTime, y=df.MACD, name='MACD'), row=2, col=1)\n",
        "    fig.add_trace(go.Scatter(x=df.DateTime, y=df.MACD_signal, name='Signal line'), row=2, col=1)\n",
        "    fig.show()\n",
        "\n",
        "# plotMACD(ES_1hour_raw)\n",
        "# plotMACD(NQ_1hour_raw)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## IV. Stochastic\n",
        "\n",
        "The last technical tool in this notebook is a stochastic oscillator is quite similar to RSI in the sense that it's values (also in range 0-100) can indicate whether a stock is overbought/oversold or not. It is arguably the most complicated indicator compared to the ones introduced earlier. Stochastic can be calculated as:\n",
        "\n",
        "$$\\%K=\\frac{C−L_{14}}{H_{14}−L_{14}}×100$$\n",
        " \n",
        "where:  $C$\n",
        "  is the most recent close price,  $L_{14}$\n",
        "  and  $H_{14}$\n",
        "  are the lowest/highest prices traded in last 14 days.\n",
        "\n",
        "This  $%K$\n",
        "  stochastic is often referred as the \"slow stochastic indicator\". There is also a \"fast stochastic indicator\" that can be obtained as:\n",
        "\n",
        "$$\\%D=SMA_3(\\%K)$$"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "def calc_stochastic(df, k=14, d=3):\n",
        "    df = df.copy()\n",
        "    low_min  = df['Low'].rolling(window=k).min()\n",
        "    high_max = df['High'].rolling( window=k).max()\n",
        "    df['stoch_k'] = 100 * (df['Close'] - low_min)/(high_max - low_min)\n",
        "    df['stoch_d'] = df['stoch_k'].rolling(window=d).mean()\n",
        "\n",
        "# SnP500\n",
        "\n",
        "calc_stochastic(ES_1min_raw)\n",
        "calc_stochastic(ES_5min_raw)\n",
        "calc_stochastic(ES_30min_raw)\n",
        "calc_stochastic(ES_1hour_raw)\n",
        "\n",
        "# Nasdaq\n",
        "\n",
        "calc_stochastic(NQ_1min_raw)\n",
        "calc_stochastic(NQ_5min_raw)\n",
        "calc_stochastic(NQ_30min_raw)\n",
        "calc_stochastic(NQ_1hour_raw)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Plotting stochastics\n",
        "\n",
        "def plot_stochastic(df):\n",
        "    fig = go.Figure()\n",
        "    fig.add_trace(go.Scatter(x=df.DateTime, y=df.stoch_k, name='K stochastic'))\n",
        "    fig.add_trace(go.Scatter(x=df.DateTime, y=df.stoch_d, name='D stochastic'))\n",
        "    fig.show()\n",
        "\n",
        "# plot_stochastic(ES_5min_raw)\n",
        "# plot_stochastic(ES_1hour_raw)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## V. Differencing"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# SnP500\n",
        "\n",
        "ES_1min_raw[\"Difference\"] = ES_1min_raw.Close.diff(1)\n",
        "ES_5min_raw[\"Difference\"] = ES_5min_raw.Close.diff(1)\n",
        "ES_30min_raw[\"Difference\"] = ES_30min_raw.Close.diff(1)\n",
        "ES_1hour_raw[\"Difference\"] = ES_1hour_raw.Close.diff(1)\n",
        "\n",
        "# Nasdaq\n",
        "\n",
        "NQ_1min_raw[\"Difference\"] = NQ_1min_raw.Close.diff(1)\n",
        "NQ_5min_raw[\"Difference\"] = NQ_5min_raw.Close.diff(1)\n",
        "NQ_30min_raw[\"Difference\"] = NQ_30min_raw.Close.diff(1)\n",
        "NQ_1hour_raw[\"Difference\"] = NQ_1hour_raw.Close.diff(1)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## VI. On-Balance Volume"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "def calc_obv(df):\n",
        "    df[\"OBV\"] = np.where(df['Close'] > df['Close'].shift(1), df['Volume'], \n",
        "    np.where(df['Close'] < df['Close'].shift(1), -df['Volume'], 0)).cumsum()\n",
        "\n",
        "# SnP500\n",
        "\n",
        "calc_obv(ES_1min_raw)\n",
        "calc_obv(ES_5min_raw)\n",
        "calc_obv(ES_30min_raw)\n",
        "calc_obv(ES_1hour_raw)\n",
        "\n",
        "# Nasdaq\n",
        "\n",
        "calc_obv(NQ_1min_raw)\n",
        "calc_obv(NQ_5min_raw)\n",
        "calc_obv(NQ_30min_raw)\n",
        "calc_obv(NQ_1hour_raw)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Plotting OBV\n",
        "\n",
        "def plot_obv(df):\n",
        "    fig = go.Figure()\n",
        "    fig.add_trace(go.Scatter(x=df.DateTime, y=df.OBV))\n",
        "    fig.show()\n",
        "\n",
        "# plot_obv(ES_5min_raw)\n",
        "# plot_obv(ES_1hour_raw)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# Model Training"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## ARIMA Model parameter tuning and training"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "model = auto_arima(NQ_1hour_raw['Close'], seasonal=False, trace=True)\n",
        "print(model.summary())"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 105,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "38544 9637\n",
            "5967.67043811829\n",
            "38545 9636\n",
            "5967.477595967866\n",
            "38546 9635\n",
            "5973.651469197375\n",
            "38547 9634\n",
            "5969.939341207206\n",
            "38548 9633\n",
            "5965.883921924351\n",
            "38549 9632\n",
            "5959.820587567138\n",
            "38550 9631\n",
            "5963.554950590397\n",
            "38551 9630\n",
            "5961.459086012075\n",
            "38552 9629\n",
            "5962.261261013516\n",
            "38553 9628\n",
            "5973.025112721929\n",
            "38554 9627\n",
            "5978.70460544416\n",
            "38555 9626\n",
            "5968.024461257356\n",
            "38556 9625\n",
            "5966.922507151613\n",
            "38557 9624\n"
          ]
        },
        {
          "ename": "KeyboardInterrupt",
          "evalue": "",
          "output_type": "error",
          "traceback": [
            "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
            "Cell \u001b[1;32mIn[105], line 28\u001b[0m\n\u001b[0;32m     24\u001b[0m         \u001b[39mprint\u001b[39m(train\u001b[39m.\u001b[39msize, test\u001b[39m.\u001b[39msize)\n\u001b[0;32m     26\u001b[0m     \u001b[39mreturn\u001b[39;00m predictions\n\u001b[1;32m---> 28\u001b[0m calc_arima(NQ_1hour_raw)\n",
            "Cell \u001b[1;32mIn[105], line 18\u001b[0m, in \u001b[0;36mcalc_arima\u001b[1;34m(df)\u001b[0m\n\u001b[0;32m     15\u001b[0m predictions \u001b[39m=\u001b[39m []\n\u001b[0;32m     17\u001b[0m \u001b[39mfor\u001b[39;00m i \u001b[39min\u001b[39;00m \u001b[39mrange\u001b[39m(\u001b[39mlen\u001b[39m(test)):\n\u001b[1;32m---> 18\u001b[0m     pred \u001b[39m=\u001b[39m arima_forecast(train)\n\u001b[0;32m     19\u001b[0m     predictions\u001b[39m.\u001b[39mappend(pred)\n\u001b[0;32m     21\u001b[0m     train \u001b[39m=\u001b[39m np\u001b[39m.\u001b[39mappend(train, [ test[\u001b[39m0\u001b[39m] ])\n",
            "Cell \u001b[1;32mIn[105], line 8\u001b[0m, in \u001b[0;36mcalc_arima.<locals>.arima_forecast\u001b[1;34m(train)\u001b[0m\n\u001b[0;32m      6\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39marima_forecast\u001b[39m(train):\n\u001b[0;32m      7\u001b[0m     model \u001b[39m=\u001b[39m ARIMA(train, order\u001b[39m=\u001b[39m(\u001b[39m1\u001b[39m,\u001b[39m1\u001b[39m,\u001b[39m1\u001b[39m))\n\u001b[1;32m----> 8\u001b[0m     model_fit \u001b[39m=\u001b[39m model\u001b[39m.\u001b[39;49mfit()\n\u001b[0;32m     10\u001b[0m     output \u001b[39m=\u001b[39m model_fit\u001b[39m.\u001b[39mforecast()\n\u001b[0;32m     11\u001b[0m     yhat \u001b[39m=\u001b[39m output[\u001b[39m0\u001b[39m]\n",
            "File \u001b[1;32mc:\\Python311\\Lib\\site-packages\\statsmodels\\tsa\\arima\\model.py:395\u001b[0m, in \u001b[0;36mARIMA.fit\u001b[1;34m(self, start_params, transformed, includes_fixed, method, method_kwargs, gls, gls_kwargs, cov_type, cov_kwds, return_params, low_memory)\u001b[0m\n\u001b[0;32m    392\u001b[0m \u001b[39melse\u001b[39;00m:\n\u001b[0;32m    393\u001b[0m     method_kwargs\u001b[39m.\u001b[39msetdefault(\u001b[39m'\u001b[39m\u001b[39mdisp\u001b[39m\u001b[39m'\u001b[39m, \u001b[39m0\u001b[39m)\n\u001b[1;32m--> 395\u001b[0m     res \u001b[39m=\u001b[39m \u001b[39msuper\u001b[39;49m()\u001b[39m.\u001b[39;49mfit(\n\u001b[0;32m    396\u001b[0m         return_params\u001b[39m=\u001b[39;49mreturn_params, low_memory\u001b[39m=\u001b[39;49mlow_memory,\n\u001b[0;32m    397\u001b[0m         cov_type\u001b[39m=\u001b[39;49mcov_type, cov_kwds\u001b[39m=\u001b[39;49mcov_kwds, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mmethod_kwargs)\n\u001b[0;32m    398\u001b[0m     \u001b[39mif\u001b[39;00m \u001b[39mnot\u001b[39;00m return_params:\n\u001b[0;32m    399\u001b[0m         res\u001b[39m.\u001b[39mfit_details \u001b[39m=\u001b[39m res\u001b[39m.\u001b[39mmlefit\n",
            "File \u001b[1;32mc:\\Python311\\Lib\\site-packages\\statsmodels\\tsa\\statespace\\mlemodel.py:704\u001b[0m, in \u001b[0;36mMLEModel.fit\u001b[1;34m(self, start_params, transformed, includes_fixed, cov_type, cov_kwds, method, maxiter, full_output, disp, callback, return_params, optim_score, optim_complex_step, optim_hessian, flags, low_memory, **kwargs)\u001b[0m\n\u001b[0;32m    702\u001b[0m         flags[\u001b[39m'\u001b[39m\u001b[39mhessian_method\u001b[39m\u001b[39m'\u001b[39m] \u001b[39m=\u001b[39m optim_hessian\n\u001b[0;32m    703\u001b[0m     fargs \u001b[39m=\u001b[39m (flags,)\n\u001b[1;32m--> 704\u001b[0m     mlefit \u001b[39m=\u001b[39m \u001b[39msuper\u001b[39;49m(MLEModel, \u001b[39mself\u001b[39;49m)\u001b[39m.\u001b[39;49mfit(start_params, method\u001b[39m=\u001b[39;49mmethod,\n\u001b[0;32m    705\u001b[0m                                        fargs\u001b[39m=\u001b[39;49mfargs,\n\u001b[0;32m    706\u001b[0m                                        maxiter\u001b[39m=\u001b[39;49mmaxiter,\n\u001b[0;32m    707\u001b[0m                                        full_output\u001b[39m=\u001b[39;49mfull_output,\n\u001b[0;32m    708\u001b[0m                                        disp\u001b[39m=\u001b[39;49mdisp, callback\u001b[39m=\u001b[39;49mcallback,\n\u001b[0;32m    709\u001b[0m                                        skip_hessian\u001b[39m=\u001b[39;49m\u001b[39mTrue\u001b[39;49;00m, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n\u001b[0;32m    711\u001b[0m \u001b[39m# Just return the fitted parameters if requested\u001b[39;00m\n\u001b[0;32m    712\u001b[0m \u001b[39mif\u001b[39;00m return_params:\n",
            "File \u001b[1;32mc:\\Python311\\Lib\\site-packages\\statsmodels\\base\\model.py:566\u001b[0m, in \u001b[0;36mLikelihoodModel.fit\u001b[1;34m(self, start_params, method, maxiter, full_output, disp, fargs, callback, retall, skip_hessian, **kwargs)\u001b[0m\n\u001b[0;32m    563\u001b[0m     \u001b[39mdel\u001b[39;00m kwargs[\u001b[39m\"\u001b[39m\u001b[39muse_t\u001b[39m\u001b[39m\"\u001b[39m]\n\u001b[0;32m    565\u001b[0m optimizer \u001b[39m=\u001b[39m Optimizer()\n\u001b[1;32m--> 566\u001b[0m xopt, retvals, optim_settings \u001b[39m=\u001b[39m optimizer\u001b[39m.\u001b[39;49m_fit(f, score, start_params,\n\u001b[0;32m    567\u001b[0m                                                fargs, kwargs,\n\u001b[0;32m    568\u001b[0m                                                hessian\u001b[39m=\u001b[39;49mhess,\n\u001b[0;32m    569\u001b[0m                                                method\u001b[39m=\u001b[39;49mmethod,\n\u001b[0;32m    570\u001b[0m                                                disp\u001b[39m=\u001b[39;49mdisp,\n\u001b[0;32m    571\u001b[0m                                                maxiter\u001b[39m=\u001b[39;49mmaxiter,\n\u001b[0;32m    572\u001b[0m                                                callback\u001b[39m=\u001b[39;49mcallback,\n\u001b[0;32m    573\u001b[0m                                                retall\u001b[39m=\u001b[39;49mretall,\n\u001b[0;32m    574\u001b[0m                                                full_output\u001b[39m=\u001b[39;49mfull_output)\n\u001b[0;32m    575\u001b[0m \u001b[39m# Restore cov_type, cov_kwds and use_t\u001b[39;00m\n\u001b[0;32m    576\u001b[0m optim_settings\u001b[39m.\u001b[39mupdate(kwds)\n",
            "File \u001b[1;32mc:\\Python311\\Lib\\site-packages\\statsmodels\\base\\optimizer.py:242\u001b[0m, in \u001b[0;36mOptimizer._fit\u001b[1;34m(self, objective, gradient, start_params, fargs, kwargs, hessian, method, maxiter, full_output, disp, callback, retall)\u001b[0m\n\u001b[0;32m    239\u001b[0m     fit_funcs\u001b[39m.\u001b[39mupdate(extra_fit_funcs)\n\u001b[0;32m    241\u001b[0m func \u001b[39m=\u001b[39m fit_funcs[method]\n\u001b[1;32m--> 242\u001b[0m xopt, retvals \u001b[39m=\u001b[39m func(objective, gradient, start_params, fargs, kwargs,\n\u001b[0;32m    243\u001b[0m                      disp\u001b[39m=\u001b[39;49mdisp, maxiter\u001b[39m=\u001b[39;49mmaxiter, callback\u001b[39m=\u001b[39;49mcallback,\n\u001b[0;32m    244\u001b[0m                      retall\u001b[39m=\u001b[39;49mretall, full_output\u001b[39m=\u001b[39;49mfull_output,\n\u001b[0;32m    245\u001b[0m                      hess\u001b[39m=\u001b[39;49mhessian)\n\u001b[0;32m    247\u001b[0m optim_settings \u001b[39m=\u001b[39m {\u001b[39m'\u001b[39m\u001b[39moptimizer\u001b[39m\u001b[39m'\u001b[39m: method, \u001b[39m'\u001b[39m\u001b[39mstart_params\u001b[39m\u001b[39m'\u001b[39m: start_params,\n\u001b[0;32m    248\u001b[0m                   \u001b[39m'\u001b[39m\u001b[39mmaxiter\u001b[39m\u001b[39m'\u001b[39m: maxiter, \u001b[39m'\u001b[39m\u001b[39mfull_output\u001b[39m\u001b[39m'\u001b[39m: full_output,\n\u001b[0;32m    249\u001b[0m                   \u001b[39m'\u001b[39m\u001b[39mdisp\u001b[39m\u001b[39m'\u001b[39m: disp, \u001b[39m'\u001b[39m\u001b[39mfargs\u001b[39m\u001b[39m'\u001b[39m: fargs, \u001b[39m'\u001b[39m\u001b[39mcallback\u001b[39m\u001b[39m'\u001b[39m: callback,\n\u001b[0;32m    250\u001b[0m                   \u001b[39m'\u001b[39m\u001b[39mretall\u001b[39m\u001b[39m'\u001b[39m: retall, \u001b[39m\"\u001b[39m\u001b[39mextra_fit_funcs\u001b[39m\u001b[39m\"\u001b[39m: extra_fit_funcs}\n\u001b[0;32m    251\u001b[0m optim_settings\u001b[39m.\u001b[39mupdate(kwargs)\n",
            "File \u001b[1;32mc:\\Python311\\Lib\\site-packages\\statsmodels\\base\\optimizer.py:659\u001b[0m, in \u001b[0;36m_fit_lbfgs\u001b[1;34m(f, score, start_params, fargs, kwargs, disp, maxiter, callback, retall, full_output, hess)\u001b[0m\n\u001b[0;32m    656\u001b[0m \u001b[39melif\u001b[39;00m approx_grad:\n\u001b[0;32m    657\u001b[0m     func \u001b[39m=\u001b[39m f\n\u001b[1;32m--> 659\u001b[0m retvals \u001b[39m=\u001b[39m optimize\u001b[39m.\u001b[39;49mfmin_l_bfgs_b(func, start_params, maxiter\u001b[39m=\u001b[39;49mmaxiter,\n\u001b[0;32m    660\u001b[0m                                  callback\u001b[39m=\u001b[39;49mcallback, args\u001b[39m=\u001b[39;49mfargs,\n\u001b[0;32m    661\u001b[0m                                  bounds\u001b[39m=\u001b[39;49mbounds, disp\u001b[39m=\u001b[39;49mdisp,\n\u001b[0;32m    662\u001b[0m                                  \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mextra_kwargs)\n\u001b[0;32m    664\u001b[0m \u001b[39mif\u001b[39;00m full_output:\n\u001b[0;32m    665\u001b[0m     xopt, fopt, d \u001b[39m=\u001b[39m retvals\n",
            "File \u001b[1;32mc:\\Python311\\Lib\\site-packages\\scipy\\optimize\\_lbfgsb_py.py:199\u001b[0m, in \u001b[0;36mfmin_l_bfgs_b\u001b[1;34m(func, x0, fprime, args, approx_grad, bounds, m, factr, pgtol, epsilon, iprint, maxfun, maxiter, disp, callback, maxls)\u001b[0m\n\u001b[0;32m    187\u001b[0m callback \u001b[39m=\u001b[39m _wrap_callback(callback)\n\u001b[0;32m    188\u001b[0m opts \u001b[39m=\u001b[39m {\u001b[39m'\u001b[39m\u001b[39mdisp\u001b[39m\u001b[39m'\u001b[39m: disp,\n\u001b[0;32m    189\u001b[0m         \u001b[39m'\u001b[39m\u001b[39miprint\u001b[39m\u001b[39m'\u001b[39m: iprint,\n\u001b[0;32m    190\u001b[0m         \u001b[39m'\u001b[39m\u001b[39mmaxcor\u001b[39m\u001b[39m'\u001b[39m: m,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    196\u001b[0m         \u001b[39m'\u001b[39m\u001b[39mcallback\u001b[39m\u001b[39m'\u001b[39m: callback,\n\u001b[0;32m    197\u001b[0m         \u001b[39m'\u001b[39m\u001b[39mmaxls\u001b[39m\u001b[39m'\u001b[39m: maxls}\n\u001b[1;32m--> 199\u001b[0m res \u001b[39m=\u001b[39m _minimize_lbfgsb(fun, x0, args\u001b[39m=\u001b[39;49margs, jac\u001b[39m=\u001b[39;49mjac, bounds\u001b[39m=\u001b[39;49mbounds,\n\u001b[0;32m    200\u001b[0m                        \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mopts)\n\u001b[0;32m    201\u001b[0m d \u001b[39m=\u001b[39m {\u001b[39m'\u001b[39m\u001b[39mgrad\u001b[39m\u001b[39m'\u001b[39m: res[\u001b[39m'\u001b[39m\u001b[39mjac\u001b[39m\u001b[39m'\u001b[39m],\n\u001b[0;32m    202\u001b[0m      \u001b[39m'\u001b[39m\u001b[39mtask\u001b[39m\u001b[39m'\u001b[39m: res[\u001b[39m'\u001b[39m\u001b[39mmessage\u001b[39m\u001b[39m'\u001b[39m],\n\u001b[0;32m    203\u001b[0m      \u001b[39m'\u001b[39m\u001b[39mfuncalls\u001b[39m\u001b[39m'\u001b[39m: res[\u001b[39m'\u001b[39m\u001b[39mnfev\u001b[39m\u001b[39m'\u001b[39m],\n\u001b[0;32m    204\u001b[0m      \u001b[39m'\u001b[39m\u001b[39mnit\u001b[39m\u001b[39m'\u001b[39m: res[\u001b[39m'\u001b[39m\u001b[39mnit\u001b[39m\u001b[39m'\u001b[39m],\n\u001b[0;32m    205\u001b[0m      \u001b[39m'\u001b[39m\u001b[39mwarnflag\u001b[39m\u001b[39m'\u001b[39m: res[\u001b[39m'\u001b[39m\u001b[39mstatus\u001b[39m\u001b[39m'\u001b[39m]}\n\u001b[0;32m    206\u001b[0m f \u001b[39m=\u001b[39m res[\u001b[39m'\u001b[39m\u001b[39mfun\u001b[39m\u001b[39m'\u001b[39m]\n",
            "File \u001b[1;32mc:\\Python311\\Lib\\site-packages\\scipy\\optimize\\_lbfgsb_py.py:361\u001b[0m, in \u001b[0;36m_minimize_lbfgsb\u001b[1;34m(fun, x0, args, jac, bounds, disp, maxcor, ftol, gtol, eps, maxfun, maxiter, iprint, callback, maxls, finite_diff_rel_step, **unknown_options)\u001b[0m\n\u001b[0;32m    355\u001b[0m task_str \u001b[39m=\u001b[39m task\u001b[39m.\u001b[39mtobytes()\n\u001b[0;32m    356\u001b[0m \u001b[39mif\u001b[39;00m task_str\u001b[39m.\u001b[39mstartswith(\u001b[39mb\u001b[39m\u001b[39m'\u001b[39m\u001b[39mFG\u001b[39m\u001b[39m'\u001b[39m):\n\u001b[0;32m    357\u001b[0m     \u001b[39m# The minimization routine wants f and g at the current x.\u001b[39;00m\n\u001b[0;32m    358\u001b[0m     \u001b[39m# Note that interruptions due to maxfun are postponed\u001b[39;00m\n\u001b[0;32m    359\u001b[0m     \u001b[39m# until the completion of the current minimization iteration.\u001b[39;00m\n\u001b[0;32m    360\u001b[0m     \u001b[39m# Overwrite f and g:\u001b[39;00m\n\u001b[1;32m--> 361\u001b[0m     f, g \u001b[39m=\u001b[39m func_and_grad(x)\n\u001b[0;32m    362\u001b[0m \u001b[39melif\u001b[39;00m task_str\u001b[39m.\u001b[39mstartswith(\u001b[39mb\u001b[39m\u001b[39m'\u001b[39m\u001b[39mNEW_X\u001b[39m\u001b[39m'\u001b[39m):\n\u001b[0;32m    363\u001b[0m     \u001b[39m# new iteration\u001b[39;00m\n\u001b[0;32m    364\u001b[0m     n_iterations \u001b[39m+\u001b[39m\u001b[39m=\u001b[39m \u001b[39m1\u001b[39m\n",
            "File \u001b[1;32mc:\\Python311\\Lib\\site-packages\\scipy\\optimize\\_differentiable_functions.py:286\u001b[0m, in \u001b[0;36mScalarFunction.fun_and_grad\u001b[1;34m(self, x)\u001b[0m\n\u001b[0;32m    284\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_update_x_impl(x)\n\u001b[0;32m    285\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_update_fun()\n\u001b[1;32m--> 286\u001b[0m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_update_grad()\n\u001b[0;32m    287\u001b[0m \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mf, \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mg\n",
            "File \u001b[1;32mc:\\Python311\\Lib\\site-packages\\scipy\\optimize\\_differentiable_functions.py:256\u001b[0m, in \u001b[0;36mScalarFunction._update_grad\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    254\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39m_update_grad\u001b[39m(\u001b[39mself\u001b[39m):\n\u001b[0;32m    255\u001b[0m     \u001b[39mif\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mg_updated:\n\u001b[1;32m--> 256\u001b[0m         \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_update_grad_impl()\n\u001b[0;32m    257\u001b[0m         \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mg_updated \u001b[39m=\u001b[39m \u001b[39mTrue\u001b[39;00m\n",
            "File \u001b[1;32mc:\\Python311\\Lib\\site-packages\\scipy\\optimize\\_differentiable_functions.py:173\u001b[0m, in \u001b[0;36mScalarFunction.__init__.<locals>.update_grad\u001b[1;34m()\u001b[0m\n\u001b[0;32m    171\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_update_fun()\n\u001b[0;32m    172\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mngev \u001b[39m+\u001b[39m\u001b[39m=\u001b[39m \u001b[39m1\u001b[39m\n\u001b[1;32m--> 173\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mg \u001b[39m=\u001b[39m approx_derivative(fun_wrapped, \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mx, f0\u001b[39m=\u001b[39;49m\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mf,\n\u001b[0;32m    174\u001b[0m                            \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mfinite_diff_options)\n",
            "File \u001b[1;32mc:\\Python311\\Lib\\site-packages\\scipy\\optimize\\_numdiff.py:505\u001b[0m, in \u001b[0;36mapprox_derivative\u001b[1;34m(fun, x0, method, rel_step, abs_step, f0, bounds, sparsity, as_linear_operator, args, kwargs)\u001b[0m\n\u001b[0;32m    502\u001b[0m     use_one_sided \u001b[39m=\u001b[39m \u001b[39mFalse\u001b[39;00m\n\u001b[0;32m    504\u001b[0m \u001b[39mif\u001b[39;00m sparsity \u001b[39mis\u001b[39;00m \u001b[39mNone\u001b[39;00m:\n\u001b[1;32m--> 505\u001b[0m     \u001b[39mreturn\u001b[39;00m _dense_difference(fun_wrapped, x0, f0, h,\n\u001b[0;32m    506\u001b[0m                              use_one_sided, method)\n\u001b[0;32m    507\u001b[0m \u001b[39melse\u001b[39;00m:\n\u001b[0;32m    508\u001b[0m     \u001b[39mif\u001b[39;00m \u001b[39mnot\u001b[39;00m issparse(sparsity) \u001b[39mand\u001b[39;00m \u001b[39mlen\u001b[39m(sparsity) \u001b[39m==\u001b[39m \u001b[39m2\u001b[39m:\n",
            "File \u001b[1;32mc:\\Python311\\Lib\\site-packages\\scipy\\optimize\\_numdiff.py:576\u001b[0m, in \u001b[0;36m_dense_difference\u001b[1;34m(fun, x0, f0, h, use_one_sided, method)\u001b[0m\n\u001b[0;32m    574\u001b[0m     x \u001b[39m=\u001b[39m x0 \u001b[39m+\u001b[39m h_vecs[i]\n\u001b[0;32m    575\u001b[0m     dx \u001b[39m=\u001b[39m x[i] \u001b[39m-\u001b[39m x0[i]  \u001b[39m# Recompute dx as exactly representable number.\u001b[39;00m\n\u001b[1;32m--> 576\u001b[0m     df \u001b[39m=\u001b[39m fun(x) \u001b[39m-\u001b[39m f0\n\u001b[0;32m    577\u001b[0m \u001b[39melif\u001b[39;00m method \u001b[39m==\u001b[39m \u001b[39m'\u001b[39m\u001b[39m3-point\u001b[39m\u001b[39m'\u001b[39m \u001b[39mand\u001b[39;00m use_one_sided[i]:\n\u001b[0;32m    578\u001b[0m     x1 \u001b[39m=\u001b[39m x0 \u001b[39m+\u001b[39m h_vecs[i]\n",
            "File \u001b[1;32mc:\\Python311\\Lib\\site-packages\\scipy\\optimize\\_numdiff.py:456\u001b[0m, in \u001b[0;36mapprox_derivative.<locals>.fun_wrapped\u001b[1;34m(x)\u001b[0m\n\u001b[0;32m    455\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mfun_wrapped\u001b[39m(x):\n\u001b[1;32m--> 456\u001b[0m     f \u001b[39m=\u001b[39m np\u001b[39m.\u001b[39matleast_1d(fun(x, \u001b[39m*\u001b[39;49margs, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs))\n\u001b[0;32m    457\u001b[0m     \u001b[39mif\u001b[39;00m f\u001b[39m.\u001b[39mndim \u001b[39m>\u001b[39m \u001b[39m1\u001b[39m:\n\u001b[0;32m    458\u001b[0m         \u001b[39mraise\u001b[39;00m \u001b[39mRuntimeError\u001b[39;00m(\u001b[39m\"\u001b[39m\u001b[39m`fun` return value has \u001b[39m\u001b[39m\"\u001b[39m\n\u001b[0;32m    459\u001b[0m                            \u001b[39m\"\u001b[39m\u001b[39mmore than 1 dimension.\u001b[39m\u001b[39m\"\u001b[39m)\n",
            "File \u001b[1;32mc:\\Python311\\Lib\\site-packages\\scipy\\optimize\\_differentiable_functions.py:137\u001b[0m, in \u001b[0;36mScalarFunction.__init__.<locals>.fun_wrapped\u001b[1;34m(x)\u001b[0m\n\u001b[0;32m    133\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mnfev \u001b[39m+\u001b[39m\u001b[39m=\u001b[39m \u001b[39m1\u001b[39m\n\u001b[0;32m    134\u001b[0m \u001b[39m# Send a copy because the user may overwrite it.\u001b[39;00m\n\u001b[0;32m    135\u001b[0m \u001b[39m# Overwriting results in undefined behaviour because\u001b[39;00m\n\u001b[0;32m    136\u001b[0m \u001b[39m# fun(self.x) will change self.x, with the two no longer linked.\u001b[39;00m\n\u001b[1;32m--> 137\u001b[0m fx \u001b[39m=\u001b[39m fun(np\u001b[39m.\u001b[39;49mcopy(x), \u001b[39m*\u001b[39;49margs)\n\u001b[0;32m    138\u001b[0m \u001b[39m# Make sure the function returns a true scalar\u001b[39;00m\n\u001b[0;32m    139\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mnot\u001b[39;00m np\u001b[39m.\u001b[39misscalar(fx):\n",
            "File \u001b[1;32mc:\\Python311\\Lib\\site-packages\\statsmodels\\base\\model.py:534\u001b[0m, in \u001b[0;36mLikelihoodModel.fit.<locals>.f\u001b[1;34m(params, *args)\u001b[0m\n\u001b[0;32m    533\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mf\u001b[39m(params, \u001b[39m*\u001b[39margs):\n\u001b[1;32m--> 534\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39m-\u001b[39m\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mloglike(params, \u001b[39m*\u001b[39;49margs) \u001b[39m/\u001b[39m nobs\n",
            "File \u001b[1;32mc:\\Python311\\Lib\\site-packages\\statsmodels\\tsa\\statespace\\mlemodel.py:939\u001b[0m, in \u001b[0;36mMLEModel.loglike\u001b[1;34m(self, params, *args, **kwargs)\u001b[0m\n\u001b[0;32m    936\u001b[0m \u001b[39mif\u001b[39;00m complex_step:\n\u001b[0;32m    937\u001b[0m     kwargs[\u001b[39m'\u001b[39m\u001b[39minversion_method\u001b[39m\u001b[39m'\u001b[39m] \u001b[39m=\u001b[39m INVERT_UNIVARIATE \u001b[39m|\u001b[39m SOLVE_LU\n\u001b[1;32m--> 939\u001b[0m loglike \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mssm\u001b[39m.\u001b[39;49mloglike(complex_step\u001b[39m=\u001b[39;49mcomplex_step, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n\u001b[0;32m    941\u001b[0m \u001b[39m# Koopman, Shephard, and Doornik recommend maximizing the average\u001b[39;00m\n\u001b[0;32m    942\u001b[0m \u001b[39m# likelihood to avoid scale issues, but the averaging is done\u001b[39;00m\n\u001b[0;32m    943\u001b[0m \u001b[39m# automatically in the base model `fit` method\u001b[39;00m\n\u001b[0;32m    944\u001b[0m \u001b[39mreturn\u001b[39;00m loglike\n",
            "File \u001b[1;32mc:\\Python311\\Lib\\site-packages\\statsmodels\\tsa\\statespace\\kalman_filter.py:1001\u001b[0m, in \u001b[0;36mKalmanFilter.loglike\u001b[1;34m(self, **kwargs)\u001b[0m\n\u001b[0;32m    985\u001b[0m \u001b[39m\u001b[39m\u001b[39mr\u001b[39m\u001b[39m\"\"\"\u001b[39;00m\n\u001b[0;32m    986\u001b[0m \u001b[39mCalculate the loglikelihood associated with the statespace model.\u001b[39;00m\n\u001b[0;32m    987\u001b[0m \n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    997\u001b[0m \u001b[39m    The joint loglikelihood.\u001b[39;00m\n\u001b[0;32m    998\u001b[0m \u001b[39m\"\"\"\u001b[39;00m\n\u001b[0;32m    999\u001b[0m kwargs\u001b[39m.\u001b[39msetdefault(\u001b[39m'\u001b[39m\u001b[39mconserve_memory\u001b[39m\u001b[39m'\u001b[39m,\n\u001b[0;32m   1000\u001b[0m                   MEMORY_CONSERVE \u001b[39m^\u001b[39m MEMORY_NO_LIKELIHOOD)\n\u001b[1;32m-> 1001\u001b[0m kfilter \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_filter(\u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n\u001b[0;32m   1002\u001b[0m loglikelihood_burn \u001b[39m=\u001b[39m kwargs\u001b[39m.\u001b[39mget(\u001b[39m'\u001b[39m\u001b[39mloglikelihood_burn\u001b[39m\u001b[39m'\u001b[39m,\n\u001b[0;32m   1003\u001b[0m                                 \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mloglikelihood_burn)\n\u001b[0;32m   1004\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mnot\u001b[39;00m (kwargs[\u001b[39m'\u001b[39m\u001b[39mconserve_memory\u001b[39m\u001b[39m'\u001b[39m] \u001b[39m&\u001b[39m MEMORY_NO_LIKELIHOOD):\n",
            "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
          ]
        }
      ],
      "source": [
        "def calc_arima(df):\n",
        "    lis = df.Close.values\n",
        "    train, test_raw = lis[:int(lis.size*0.8)], lis[int(lis.size*0.8):]\n",
        "    print(train.size, test.size)\n",
        "\n",
        "    def arima_forecast(train):\n",
        "        model = ARIMA(train, order=(1,1,1))\n",
        "        model_fit = model.fit()\n",
        "\n",
        "        output = model_fit.forecast()\n",
        "        yhat = output[0]\n",
        "        print(yhat)\n",
        "        return yhat\n",
        "\n",
        "    predictions = []\n",
        "    test = test_raw[:]\n",
        "\n",
        "    for i in range(len(test)):\n",
        "        pred = arima_forecast(train)\n",
        "        predictions.append(pred)\n",
        "\n",
        "        train = np.append(train, [ test[0] ])\n",
        "        test = test[1:]\n",
        "\n",
        "        print(train.size, test.size)\n",
        "    \n",
        "    return predictions\n",
        "\n",
        "calc_arima(NQ_1hour_raw)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": []
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.11.4"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
